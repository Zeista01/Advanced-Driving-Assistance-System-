{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Cruise Control with Depth Camera in CARLA\n",
    "\n",
    "This notebook implements an ACC system that only uses synchronous mode during the simulation phase, not during vehicle spawning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import queue\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla\n",
    "\n",
    "# Define synchronous mode manager class - will only be used during PID simulation\n",
    "class CarlaSyncMode(object):\n",
    "    \"\"\"\n",
    "    Context manager to synchronize output from different sensors. Synchronous\n",
    "    mode is enabled as long as we are inside this context\n",
    "    \"\"\"\n",
    "    def __init__(self, world, *sensors, **kwargs):\n",
    "        self.world = world\n",
    "        self.sensors = sensors\n",
    "        self.frame = None\n",
    "        self.delta_seconds = 1.0 / kwargs.get('fps', 20)\n",
    "        self._queues = []\n",
    "        self._settings = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._settings = self.world.get_settings()\n",
    "        self.frame = self.world.apply_settings(carla.WorldSettings(\n",
    "            no_rendering_mode=False,\n",
    "            synchronous_mode=True,\n",
    "            fixed_delta_seconds=self.delta_seconds))\n",
    "\n",
    "        def make_queue(register_event):\n",
    "            q = queue.Queue()\n",
    "            register_event(q.put)\n",
    "            self._queues.append(q)\n",
    "\n",
    "        make_queue(self.world.on_tick)\n",
    "        for sensor in self.sensors:\n",
    "            make_queue(sensor.listen)\n",
    "        return self\n",
    "\n",
    "    def tick(self, timeout):\n",
    "        self.frame = self.world.tick()\n",
    "        data = [self._retrieve_data(q, timeout) for q in self._queues]\n",
    "        assert all(x.frame == self.frame for x in data)\n",
    "        return data\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.world.apply_settings(self._settings)\n",
    "\n",
    "    def _retrieve_data(self, sensor_queue, timeout):\n",
    "        while True:\n",
    "            data = sensor_queue.get(timeout=timeout)\n",
    "            if data.frame == self.frame:\n",
    "                return data\n",
    "\n",
    "print(\"Dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to CARLA: Client version 0.9.15-228-geeb507e58, Server version 0.9.15-228-geeb507e58\n",
      "Connected to CARLA successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to track actors and sensors\n",
    "actor_list = []\n",
    "sensor_list = []\n",
    "\n",
    "# Connect to CARLA server (using explicit IPv4 address)\n",
    "client = carla.Client('127.0.0.1', 2000)\n",
    "client.set_timeout(20.0)  # Increase timeout for better stability\n",
    "\n",
    "# Check client and server versions\n",
    "client_version = client.get_client_version()\n",
    "server_version = client.get_server_version()\n",
    "print(f\"Connected to CARLA: Client version {client_version}, Server version {server_version}\")\n",
    "\n",
    "# Get world\n",
    "world = client.get_world()\n",
    "\n",
    "# Get blueprint library\n",
    "blueprints = world.get_blueprint_library()\n",
    "\n",
    "# Store original settings to restore later\n",
    "original_settings = world.get_settings()\n",
    "\n",
    "print(\"Connected to CARLA successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up Specific Spawn Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawn points set up successfully!\n",
      "Ego vehicle spawn location: Location(x=48.546078, y=140.975540, z=0.600001)\n",
      "Lead vehicle spawn location: Location(x=63.546078, y=140.975540, z=0.600001)\n"
     ]
    }
   ],
   "source": [
    "# Get spawn points\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "if not spawn_points:\n",
    "    print(\"No spawn points available.\")\n",
    "else:\n",
    "    # Set up specific spawn points\n",
    "    ego_spawn_point = spawn_points[20]\n",
    "    lead_spawn_point = carla.Transform(\n",
    "        ego_spawn_point.location - carla.Location(x=-15),\n",
    "        ego_spawn_point.rotation\n",
    "    )\n",
    "    print(f\"Spawn points set up successfully!\")\n",
    "    print(f\"Ego vehicle spawn location: {ego_spawn_point.location}\")\n",
    "    print(f\"Lead vehicle spawn location: {lead_spawn_point.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transfer to That Location (Set Spectator View)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectator view set successfully!\n"
     ]
    }
   ],
   "source": [
    "# Move spectator to view the spawn points\n",
    "spectator = world.get_spectator()\n",
    "spectator_transform = carla.Transform(\n",
    "    ego_spawn_point.location + carla.Location(z=50, x=-15), \n",
    "    carla.Rotation(pitch=-90)\n",
    ")\n",
    "spectator.set_transform(spectator_transform)\n",
    "print(\"Spectator view set successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spawn Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ego vehicle spawned: vehicle.dodge.charger_2020\n",
      "Lead vehicle spawned: vehicle.jeep.wrangler_rubicon\n",
      "Vehicles spawned successfully!\n"
     ]
    }
   ],
   "source": [
    "# Important: Use asynchronous mode for vehicle spawning (synchronous mode crashes)\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False  # Make sure we're in asynchronous mode\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# Create ego vehicle\n",
    "ego_blueprint = blueprints.filter('vehicle.dodge.charger_2020')[0]\n",
    "ego_vehicle = world.spawn_actor(ego_blueprint, ego_spawn_point)\n",
    "ego_vehicle.set_autopilot(False)\n",
    "actor_list.append(ego_vehicle)\n",
    "print(f\"Ego vehicle spawned: {ego_vehicle.type_id}\")\n",
    "\n",
    "# Create lead vehicle\n",
    "lead_blueprint = blueprints.filter('vehicle.jeep.wrangler_rubicon')[0]\n",
    "lead_vehicle = world.spawn_actor(lead_blueprint, lead_spawn_point)\n",
    "actor_list.append(lead_vehicle)\n",
    "print(f\"Lead vehicle spawned: {lead_vehicle.type_id}\")\n",
    "\n",
    "# Wait a moment for vehicle spawning to complete\n",
    "time.sleep(1.0)\n",
    "\n",
    "print(\"Vehicles spawned successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle.destroy()\n",
    "lead_vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Camera and Distance Measurement Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cameras and distance measurement set up successfully!\n"
     ]
    }
   ],
   "source": [
    "def process_depth_image(depth_image, prev_lead_x=None):\n",
    "    \"\"\"\n",
    "    Process the depth image from CARLA's depth camera to extract distance information\n",
    "    with improved lead vehicle tracking during turns\n",
    "    \n",
    "    Args:\n",
    "        depth_image: Image from CARLA depth camera\n",
    "        prev_lead_x: Previous x-position of lead vehicle in image (for tracking)\n",
    "        \n",
    "    Returns:\n",
    "        processed_image, distance_to_object, lead_vehicle_x_position\n",
    "    \"\"\"\n",
    "    # Convert depth image to numpy array\n",
    "    depth_array = np.frombuffer(depth_image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    depth_array = np.reshape(depth_array, (depth_image.height, depth_image.width, 4))\n",
    "    \n",
    "    # Extract RGB channels (first 3 channels)\n",
    "    depth_array = depth_array[:, :, :3]\n",
    "    \n",
    "    # According to CARLA documentation:\n",
    "    # normalized = (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1)\n",
    "    # in_meters = 1000 * normalized\n",
    "    \n",
    "    # Extract R, G, B channels\n",
    "    r = depth_array[:, :, 2].astype(np.float32)  # Red channel\n",
    "    g = depth_array[:, :, 1].astype(np.float32)  # Green channel\n",
    "    b = depth_array[:, :, 0].astype(np.float32)  # Blue channel\n",
    "    \n",
    "    # Calculate normalized depth\n",
    "    normalized = (r + g * 256 + b * 256 * 256) / (256 * 256 * 256 - 1)\n",
    "    \n",
    "    # Convert to distance in meters\n",
    "    depth_meters = 1000 * normalized\n",
    "    \n",
    "    # Create grayscale visualization (closer=black, farther=white)\n",
    "    depth_visualization = (normalized * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert to 3-channel grayscale for display compatibility\n",
    "    depth_visualization = cv2.cvtColor(depth_visualization, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Setup basic ROI dimensions\n",
    "    center_h = depth_image.height // 2\n",
    "    center_w = depth_image.width // 2\n",
    "    roi_h = 100  # Height of ROI\n",
    "    roi_w = 200  # Width of ROI\n",
    "    \n",
    "    # Dynamic ROI adjustment based on previous lead vehicle position\n",
    "    if prev_lead_x is not None and prev_lead_x > 1:\n",
    "        x_shift = int((prev_lead_x - center_w) * 0.3)  # Smooth tracking with 0.3 factor\n",
    "        roi_w_start = max(0, center_w - roi_w//2 + x_shift)\n",
    "        roi_w_end = min(depth_image.width, center_w + roi_w//2 + x_shift)\n",
    "    else:\n",
    "        roi_w_start = center_w - roi_w//2\n",
    "        roi_w_end = center_w + roi_w//2\n",
    "\n",
    "    # Extract ROI from depth image\n",
    "    roi = depth_meters[\n",
    "        center_h - roi_h//2:center_h + roi_h//2,\n",
    "        roi_w_start:roi_w_end\n",
    "    ]\n",
    "    \n",
    "    # Draw ROI rectangle on visualization\n",
    "    cv2.rectangle(\n",
    "        depth_visualization, \n",
    "        (roi_w_start, center_h - roi_h//2), \n",
    "        (roi_w_end, center_h + roi_h//2), \n",
    "        (0, 255, 0), \n",
    "        2\n",
    "    )\n",
    "    \n",
    "    # Filter unrealistic distances (0 and > 100m)\n",
    "    roi_filtered = roi.copy()\n",
    "    roi_filtered[roi_filtered < 0.1] = 100  # Set very close/invalid pixels to far distance\n",
    "    roi_filtered[roi_filtered > 100] = 100  # Cap maximum distance\n",
    "    \n",
    "    # Find minimum distance to object within filtered ROI\n",
    "    min_distance = np.min(roi_filtered)\n",
    "    if min_distance >= 100:\n",
    "        min_distance = 100  # No object detected within reasonable range\n",
    "    \n",
    "    # Find position of closest object for tracking in next frame\n",
    "    lead_x = None\n",
    "    if roi_filtered.size > 0:\n",
    "        min_idx = np.unravel_index(np.argmin(roi_filtered), roi_filtered.shape)\n",
    "        lead_x = roi_w_start + min_idx[1]  # Horizontal position of lead vehicle\n",
    "        \n",
    "        # Draw a marker at the closest point\n",
    "        marker_y = center_h - roi_h//2 + min_idx[0]\n",
    "        cv2.circle(depth_visualization, (lead_x, marker_y), 5, (0, 0, 255), -1)\n",
    "    \n",
    "    return depth_visualization, min_distance, lead_x\n",
    "\n",
    "\n",
    "# Add RGB camera to ego vehicle\n",
    "camera_bp = blueprints.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '800')\n",
    "camera_bp.set_attribute('image_size_y', '600')\n",
    "camera_bp.set_attribute('fov', '110')\n",
    "camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))\n",
    "camera_rgb = world.spawn_actor(camera_bp, camera_transform, attach_to=ego_vehicle)\n",
    "sensor_list.append(camera_rgb)\n",
    "\n",
    "# Add depth camera to ego vehicle for distance measurement\n",
    "depth_camera_bp = blueprints.find('sensor.camera.depth')\n",
    "depth_camera_bp.set_attribute('image_size_x', '800')\n",
    "depth_camera_bp.set_attribute('image_size_y', '600')\n",
    "depth_camera_bp.set_attribute('fov', '110')\n",
    "depth_camera = world.spawn_actor(depth_camera_bp, camera_transform, attach_to=ego_vehicle)\n",
    "sensor_list.append(depth_camera)\n",
    "\n",
    "# Variables to store camera data\n",
    "image_w = int(camera_bp.get_attribute('image_size_x').as_int())\n",
    "image_h = int(camera_bp.get_attribute('image_size_y').as_int())\n",
    "\n",
    "# Wait for a moment to make sure sensors are properly initialized\n",
    "time.sleep(0.5)\n",
    "\n",
    "print(\"Cameras and distance measurement set up successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Set Up PID Control for Ego Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID controller set up for ego vehicle!\n"
     ]
    }
   ],
   "source": [
    "# PID Controller for vehicle control\n",
    "class PIDController:\n",
    "    def __init__(self, Kp, Ki, Kd, dt):\n",
    "        self.Kp = Kp\n",
    "        self.Ki = Ki\n",
    "        self.Kd = Kd\n",
    "        self.dt = dt\n",
    "        self.previous_error = 0\n",
    "        self.integral = 0\n",
    "        self.integral_max = 10.0  # Anti-windup limit\n",
    "        \n",
    "    def step(self, error):\n",
    "        # Proportional term\n",
    "        P = self.Kp * error\n",
    "        \n",
    "        # Integral term with anti-windup\n",
    "        self.integral += error * self.dt\n",
    "        self.integral = max(-self.integral_max, min(self.integral_max, self.integral))  # Clamp integral\n",
    "        I = self.Ki * self.integral\n",
    "        \n",
    "        # Derivative term\n",
    "        derivative = (error - self.previous_error) / self.dt\n",
    "        D = self.Kd * derivative\n",
    "        \n",
    "        # Total output\n",
    "        output = P + I + D\n",
    "        \n",
    "        # Save error for next iteration\n",
    "        self.previous_error = error\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def reset(self):\n",
    "        self.previous_error = 0\n",
    "        self.integral = 0\n",
    "\n",
    "# Combined PID controller for vehicle control\n",
    "class VehiclePIDController:\n",
    "    def __init__(self, args_lateral, args_longitudinal, max_throttle=0.75, max_brake=0.3, max_steering=0.8):\n",
    "        self.max_throttle = max_throttle\n",
    "        self.max_brake = max_brake\n",
    "        self.max_steering = max_steering\n",
    "        \n",
    "        self.lon_controller = PIDController(\n",
    "            args_longitudinal['Kp'],\n",
    "            args_longitudinal['Ki'],\n",
    "            args_longitudinal['Kd'],\n",
    "            args_longitudinal['dt']\n",
    "        )\n",
    "        \n",
    "        self.lat_controller = PIDController(\n",
    "            args_lateral['Kp'],\n",
    "            args_lateral['Ki'],\n",
    "            args_lateral['Kd'],\n",
    "            args_lateral['dt']\n",
    "        )\n",
    "    \n",
    "    def run_step(self, target_speed, current_speed, waypoint, vehicle_transform, lead_vehicle=None):\n",
    "        \"\"\"\n",
    "        Execute one step of control with improved lead vehicle tracking during turns\n",
    "        \n",
    "        lead_vehicle: Optional lead vehicle actor to follow during turns\n",
    "        \"\"\"\n",
    "        # Longitudinal control - adjust speed\n",
    "        acceleration = self.lon_controller.step(target_speed - current_speed)\n",
    "        \n",
    "        if acceleration >= 0:\n",
    "            throttle = min(acceleration, self.max_throttle)\n",
    "            brake = 0\n",
    "        else:\n",
    "            throttle = 0\n",
    "            brake = min(abs(acceleration), self.max_brake)\n",
    "        \n",
    "        # Lateral control - adjust steering\n",
    "        # Calculate steering based on waypoint or lead vehicle position\n",
    "        v_begin = vehicle_transform.location\n",
    "        v_end = v_begin + carla.Location(x=math.cos(math.radians(vehicle_transform.rotation.yaw)),\n",
    "                                        y=math.sin(math.radians(vehicle_transform.rotation.yaw)))\n",
    "        \n",
    "        v_vec = np.array([v_end.x - v_begin.x, v_end.y - v_begin.y, 0.0])\n",
    "        \n",
    "        # Use lead vehicle position for navigation if available and within range\n",
    "        if lead_vehicle is not None:\n",
    "            lead_loc = lead_vehicle.get_location()\n",
    "            # Calculate distance to lead vehicle\n",
    "            dist_to_lead = math.sqrt((lead_loc.x - v_begin.x)**2 + (lead_loc.y - v_begin.y)**2)\n",
    "            \n",
    "            if dist_to_lead < 50.0:  # Only use lead vehicle for navigation when within 50m\n",
    "                # Add prediction to lead vehicle position based on its velocity\n",
    "                lead_vel = lead_vehicle.get_velocity()\n",
    "                prediction_time = min(dist_to_lead * 0.1, 1.0)  # Adjust prediction based on distance\n",
    "                \n",
    "                predicted_x = lead_loc.x + lead_vel.x * prediction_time\n",
    "                predicted_y = lead_loc.y + lead_vel.y * prediction_time\n",
    "                \n",
    "                # Use predicted position for steering \n",
    "                w_vec = np.array([predicted_x - v_begin.x, predicted_y - v_begin.y, 0.0])\n",
    "            else:\n",
    "                # Default to waypoint if lead vehicle is too far\n",
    "                w_vec = np.array([waypoint.transform.location.x - v_begin.x,\n",
    "                                 waypoint.transform.location.y - v_begin.y,\n",
    "                                 0.0])\n",
    "        else:\n",
    "            # Default to waypoint if no lead vehicle is provided\n",
    "            w_vec = np.array([waypoint.transform.location.x - v_begin.x,\n",
    "                             waypoint.transform.location.y - v_begin.y,\n",
    "                             0.0])\n",
    "        \n",
    "        # Normalize vectors\n",
    "        v_vec_norm = np.linalg.norm(v_vec)\n",
    "        w_vec_norm = np.linalg.norm(w_vec)\n",
    "        \n",
    "        if v_vec_norm > 0 and w_vec_norm > 0:\n",
    "            v_vec = v_vec / v_vec_norm\n",
    "            w_vec = w_vec / w_vec_norm\n",
    "            \n",
    "            # Calculate the angle\n",
    "            dot = np.clip(np.dot(v_vec, w_vec), -1.0, 1.0)\n",
    "            angle = math.acos(dot)\n",
    "            \n",
    "            # Determine sign of the angle\n",
    "            cross = np.cross(v_vec, w_vec)\n",
    "            if cross[2] < 0:\n",
    "                angle = -angle\n",
    "        else:\n",
    "            angle = 0.0\n",
    "        \n",
    "        # Apply PID to the calculated angle\n",
    "        steering = self.lat_controller.step(angle)\n",
    "        steering = max(-self.max_steering, min(self.max_steering, steering))\n",
    "        \n",
    "        control = carla.VehicleControl()\n",
    "        control.throttle = throttle\n",
    "        control.brake = brake\n",
    "        control.steer = steering\n",
    "        \n",
    "        return control\n",
    "    \n",
    "    def reset(self):\n",
    "        self.lon_controller.reset()\n",
    "        self.lat_controller.reset()\n",
    "\n",
    "# Set up PID controller parameters with improved values for turns\n",
    "args_lateral = {\n",
    "    'Kp':1,      # Increased for better turn responsiveness\n",
    "    'Ki': 0.01,     # Reduced to prevent overshoot\n",
    "    'Kd': 0.15,     # Increased for better damping\n",
    "    'dt': 0.02      # Faster update rate\n",
    "}\n",
    "\n",
    "args_longitudinal = {\n",
    "    'Kp': 0.5,\n",
    "    'Ki': 0.1,\n",
    "    'Kd': 0.005,\n",
    "    'dt': 0.05\n",
    "}\n",
    "\n",
    "vehicle_controller = VehiclePIDController(\n",
    "    args_lateral,\n",
    "    args_longitudinal,\n",
    "    max_throttle=0.75,\n",
    "    max_brake=0.3,\n",
    "    max_steering=0.8\n",
    ")\n",
    "\n",
    "# Set target distance for ACC\n",
    "target_distance = 10.0  # meters\n",
    "\n",
    "print(\"PID controller set up for ego vehicle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Implement Autopilot on Lead Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autopilot activated for lead vehicle!\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're still in asynchronous mode for setting up autopilot\n",
    "if world.get_settings().synchronous_mode:\n",
    "    settings = world.get_settings()\n",
    "    settings.synchronous_mode = False\n",
    "    world.apply_settings(settings)\n",
    "\n",
    "# Set lead vehicle to autopilot mode\n",
    "lead_vehicle.set_autopilot(True)\n",
    "\n",
    "# Adjust traffic manager parameters for the lead vehicle\n",
    "traffic_manager = client.get_trafficmanager()\n",
    "traffic_manager.global_percentage_speed_difference(30.0)  # Reduce speed by 30%\n",
    "traffic_manager.vehicle_percentage_speed_difference(lead_vehicle, 30.0)\n",
    "traffic_manager.distance_to_leading_vehicle(lead_vehicle, 2.0)\n",
    "\n",
    "# Wait for a moment to ensure autopilot is properly activated\n",
    "time.sleep(0.5)\n",
    "\n",
    "print(\"Autopilot activated for lead vehicle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Implement PID Control on Ego Vehicle and Display Results with OpenCV\n",
    "\n",
    "Now we'll enable synchronous mode ONLY for the PID simulation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started: Saving video to acc.avi\n",
      "Entered synchronous mode for PID simulation\n",
      "Starting adaptive cruise control. Press 'q' or 'ESC' to quit.\n",
      "ACC simulation completed after 2000 iterations!\n",
      "Cleaning up...\n",
      "Video saved successfully as acc.avi\n",
      "Cleanup complete!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Video Writer\n",
    "video_filename = \"acc.avi\"\n",
    "frame_width = 640\n",
    "frame_height = 360\n",
    "fps = 30  # Frames per second\n",
    "\n",
    "# Define VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for .avi format\n",
    "video_writer = cv2.VideoWriter(video_filename, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Check if VideoWriter opened successfully\n",
    "if not video_writer.isOpened():\n",
    "    print(\"Error: VideoWriter failed to open.\")\n",
    "else:\n",
    "    print(f\"Recording started: Saving video to {video_filename}\")\n",
    "\n",
    "try:\n",
    "    # Create a window for the display\n",
    "    cv2.namedWindow('Ego Vehicle Camera with Depth', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    # Initialize variables for lead vehicle tracking\n",
    "    prev_lead_x = None\n",
    "\n",
    "    # Enter synchronous mode for the simulation\n",
    "    with CarlaSyncMode(world, camera_rgb, depth_camera, fps=20) as sync_mode:\n",
    "        print(\"Entered synchronous mode for PID simulation\")\n",
    "\n",
    "        # Main control loop\n",
    "        iteration_count = 0\n",
    "        max_iterations = 2000  # Run for 2000 iterations max\n",
    "\n",
    "        print(\"Starting adaptive cruise control. Press 'q' or 'ESC' to quit.\")\n",
    "\n",
    "        # Main loop\n",
    "        while iteration_count < max_iterations:\n",
    "            iteration_count += 1\n",
    "\n",
    "            # Get synchronized data\n",
    "            snapshot, rgb_data, depth_data = sync_mode.tick(timeout=2.0)\n",
    "\n",
    "            # Process RGB image\n",
    "            rgb_array = np.frombuffer(rgb_data.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "            rgb_array = np.reshape(rgb_array, (image_h, image_w, 4))\n",
    "            rgb_array = rgb_array[:, :, :3]  # Remove alpha channel\n",
    "            rgb_image = rgb_array\n",
    "\n",
    "            # Process depth image with dynamic ROI (pass previous lead position)\n",
    "            depth_visualization, current_distance, lead_x = process_depth_image(depth_data, prev_lead_x)\n",
    "            prev_lead_x = lead_x  # Update previous lead position for next iteration\n",
    "\n",
    "            # Get current speed of ego vehicle (m/s)\n",
    "            current_speed = ego_vehicle.get_velocity().length()\n",
    "\n",
    "            # Get lead vehicle speed (m/s)\n",
    "            lead_speed = lead_vehicle.get_velocity().length()\n",
    "\n",
    "            # Calculate target speed based on distance error\n",
    "            distance_error = current_distance - target_distance\n",
    "\n",
    "            # Adaptive cruise control logic\n",
    "            if distance_error > 0:  # Too far, need to catch up\n",
    "                target_speed = min(lead_speed + 0.5 * distance_error, 30.0)  # Cap max speed\n",
    "            else:  # Too close, need to slow down\n",
    "                target_speed = max(lead_speed + 0.5 * distance_error, 0.0)  # Don't go below 0\n",
    "\n",
    "            # Get base waypoint for ego vehicle\n",
    "            ego_waypoint = world.get_map().get_waypoint(ego_vehicle.get_location())\n",
    "\n",
    "            # Get lead vehicle location for better path planning\n",
    "            lead_transform = lead_vehicle.get_transform()\n",
    "            lead_location = lead_transform.location\n",
    "\n",
    "            # Decide which waypoint to follow based on distance\n",
    "            straight_distance = math.sqrt((lead_location.x - ego_vehicle.get_location().x)**2 + \n",
    "                                         (lead_location.y - ego_vehicle.get_location().y)**2)\n",
    "\n",
    "            if straight_distance < 50.0:  # Close enough to follow lead vehicle\n",
    "                predicted_location = carla.Location(\n",
    "                    lead_location.x + lead_vehicle.get_velocity().x * 0.5,\n",
    "                    lead_location.y + lead_vehicle.get_velocity().y * 0.5,\n",
    "                    lead_location.z\n",
    "                )\n",
    "                target_waypoint = world.get_map().get_waypoint(predicted_location)\n",
    "            else:\n",
    "                target_waypoint = ego_waypoint.next(5.0)[0]  # Look 5 meters ahead\n",
    "\n",
    "            # Get control command from PID controller\n",
    "            control = vehicle_controller.run_step(\n",
    "                target_speed, \n",
    "                current_speed,\n",
    "                target_waypoint,\n",
    "                ego_vehicle.get_transform(),\n",
    "                lead_vehicle\n",
    "            )\n",
    "\n",
    "            # Apply control to ego vehicle\n",
    "            ego_vehicle.apply_control(control)\n",
    "\n",
    "            # Prepare display image\n",
    "            if rgb_image is not None and depth_visualization is not None:\n",
    "                display_img = cv2.resize(rgb_image, (frame_width, frame_height))\n",
    "\n",
    "                # Resize depth visualization to a smaller size (240x180)\n",
    "                depth_small = cv2.resize(depth_visualization, (240, 180))\n",
    "\n",
    "                # Position depth visualization at bottom right corner\n",
    "                h, w = depth_small.shape[:2]\n",
    "                display_img[frame_height - h : frame_height, frame_width - w : frame_width] = depth_small\n",
    "\n",
    "                # Add HUD information\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(display_img, f'Distance: {current_distance:.2f}m', (10, 30), font, 0.7, (0, 255, 0), 2)\n",
    "                cv2.putText(display_img, f'Speed: {current_speed * 3.6:.2f} km/h', (10, 60), font, 0.7, (0, 255, 0), 2)\n",
    "                cv2.putText(display_img, f'Target Speed: {target_speed * 3.6:.2f} km/h', (10, 90), font, 0.7, (0, 255, 0), 2)\n",
    "                cv2.putText(display_img, f'Iteration: {iteration_count}/{max_iterations}', (10, 120), font, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                # Show the image\n",
    "                cv2.imshow('Ego Vehicle Camera with Depth', display_img)\n",
    "\n",
    "                # Write frame to video file\n",
    "                video_writer.write(display_img)\n",
    "\n",
    "            # Check for key presses (quit if 'q' or ESC is pressed)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key in (27, ord('q')):\n",
    "                break\n",
    "\n",
    "        print(f\"ACC simulation completed after {iteration_count} iterations!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    print(\"Cleaning up...\")\n",
    "\n",
    "    # Ensure VideoWriter is released\n",
    "    if video_writer.isOpened():\n",
    "        video_writer.release()\n",
    "        print(f\"Video saved successfully as {video_filename}\")\n",
    "\n",
    "    # Close any remaining OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Make sure we're in asynchronous mode for cleanup\n",
    "    settings = world.get_settings()\n",
    "    if settings.synchronous_mode:\n",
    "        settings.synchronous_mode = False\n",
    "        world.apply_settings(settings)\n",
    "\n",
    "    # Turn off autopilot for lead vehicle before destroying\n",
    "    if lead_vehicle.is_alive:\n",
    "        try:\n",
    "            lead_vehicle.set_autopilot(False)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Destroy all sensors\n",
    "    for sensor in sensor_list:\n",
    "        if sensor.is_alive:\n",
    "            sensor.destroy()\n",
    "\n",
    "    # Destroy all actors\n",
    "    for actor in actor_list:\n",
    "        if actor.is_alive:\n",
    "            actor.destroy()\n",
    "\n",
    "    # Restore original settings\n",
    "    world.apply_settings(original_settings)\n",
    "\n",
    "    print(\"Cleanup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup function\n",
    "def cleanup():\n",
    "    print(\"Cleaning up...\")\n",
    "    \n",
    "    # Make sure we're in asynchronous mode for cleanup\n",
    "    settings = world.get_settings()\n",
    "    if settings.synchronous_mode:\n",
    "        settings.synchronous_mode = False\n",
    "        world.apply_settings(settings)\n",
    "    \n",
    "    # Close any remaining OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Turn off autopilot for lead vehicle before destroying\n",
    "    if lead_vehicle.is_alive:\n",
    "        try:\n",
    "            lead_vehicle.set_autopilot(False)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    # Destroy all sensors\n",
    "    for sensor in sensor_list:\n",
    "        if sensor.is_alive:\n",
    "            sensor.destroy()\n",
    "    \n",
    "    # Destroy all actors\n",
    "    for actor in actor_list:\n",
    "        if actor.is_alive:\n",
    "            actor.destroy()\n",
    "    \n",
    "    print(\"Cleanup complete!\")\n",
    "\n",
    "# Execute cleanup\n",
    "cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
